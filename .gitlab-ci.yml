# GitLab CI/CD Pipeline untuk Pinfairy Bot
# Pipeline lengkap dengan linting, testing, security scanning, dan deployment

stages:
  - validate
  - lint
  - test
  - security
  - build
  - deploy

variables:
  PIP_CACHE_DIR: "$CI_PROJECT_DIR/.cache/pip"
  DOCKER_DRIVER: overlay2
  DOCKER_TLS_CERTDIR: "/certs"

# Cache untuk mempercepat build
cache:
  paths:
    - .cache/pip
    - .venv/

# Template untuk Python jobs
.python_template: &python_template
  image: python:3.11-slim
  before_script:
    - apt-get update -qq && apt-get install -y -qq git curl build-essential
    - python -m pip install --upgrade pip
    - pip install virtualenv
    - virtualenv .venv
    - source .venv/bin/activate
    - pip install -r requirements_enhanced.txt

# ==================== VALIDATION STAGE ====================

validate:config:
  stage: validate
  <<: *python_template
  script:
    - echo "ðŸ” Validating configuration files..."
    - python -c "
      import json, yaml, os
      
      # Validate JSON files
      json_files = ['package.json'] if os.path.exists('package.json') else []
      for file in json_files:
          with open(file) as f:
              json.load(f)
              print(f'âœ… {file} is valid JSON')
      
      # Validate YAML files
      yaml_files = ['.gitlab-ci.yml']
      for file in yaml_files:
          if os.path.exists(file):
              with open(file) as f:
                  yaml.safe_load(f)
                  print(f'âœ… {file} is valid YAML')
      
      # Validate Python syntax
      import py_compile
      import glob
      
      python_files = glob.glob('**/*.py', recursive=True)
      for file in python_files:
          if not file.startswith('.venv/'):
              py_compile.compile(file, doraise=True)
              print(f'âœ… {file} syntax is valid')
      
      print('ðŸŽ‰ All configuration files are valid!')
      "
  rules:
    - changes:
        - "*.py"
        - "*.json"
        - "*.yml"
        - "*.yaml"
        - ".gitlab-ci.yml"

validate:requirements:
  stage: validate
  <<: *python_template
  script:
    - echo "ðŸ“¦ Validating Python requirements..."
    - pip-compile --version || pip install pip-tools
    - pip-compile --dry-run requirements_enhanced.txt
    - echo "âœ… Requirements are valid and resolvable"
  rules:
    - changes:
        - "requirements*.txt"
        - "pyproject.toml"

validate:imports:
  stage: validate
  <<: *python_template
  script:
    - echo "ðŸ”— Validating Python imports..."
    - python -c "
      import ast
      import glob
      import sys
      
      def check_imports(filename):
          with open(filename, 'r') as f:
              try:
                  tree = ast.parse(f.read())
                  for node in ast.walk(tree):
                      if isinstance(node, ast.Import):
                          for alias in node.names:
                              print(f'Import found in {filename}: {alias.name}')
                      elif isinstance(node, ast.ImportFrom):
                          if node.module:
                              print(f'From import found in {filename}: from {node.module} import ...')
                  return True
              except SyntaxError as e:
                  print(f'âŒ Syntax error in {filename}: {e}')
                  return False
      
      python_files = glob.glob('**/*.py', recursive=True)
      all_valid = True
      
      for file in python_files:
          if not file.startswith('.venv/') and not file.startswith('.cache/'):
              if not check_imports(file):
                  all_valid = False
      
      if all_valid:
          print('âœ… All Python imports are syntactically valid')
      else:
          print('âŒ Some files have import issues')
          sys.exit(1)
      "

# ==================== LINTING STAGE ====================

lint:flake8:
  stage: lint
  <<: *python_template
  script:
    - echo "ðŸ” Running Flake8 linting..."
    - pip install flake8 flake8-docstrings flake8-import-order flake8-bugbear
    - flake8 --version
    - |
      flake8 . \
        --count \
        --statistics \
        --show-source \
        --max-line-length=127 \
        --exclude=.git,__pycache__,.venv,venv,.env,migrations,.pytest_cache \
        --ignore=E203,W503,F401 \
        --format='%(path)s:%(row)d:%(col)d: %(code)s %(text)s'
    - echo "âœ… Flake8 linting completed"
  artifacts:
    reports:
      codequality: flake8-report.json
    when: always
    expire_in: 1 week
  allow_failure: false

lint:black:
  stage: lint
  <<: *python_template
  script:
    - echo "ðŸŽ¨ Checking code formatting with Black..."
    - pip install black
    - black --version
    - black --check --diff --color .
    - echo "âœ… Code formatting is correct"
  allow_failure: false

lint:isort:
  stage: lint
  <<: *python_template
  script:
    - echo "ðŸ“š Checking import sorting with isort..."
    - pip install isort
    - isort --version
    - isort --check-only --diff --color .
    - echo "âœ… Import sorting is correct"
  allow_failure: false

lint:mypy:
  stage: lint
  <<: *python_template
  script:
    - echo "ðŸ” Running MyPy type checking..."
    - pip install mypy types-requests
    - mypy --version
    - mypy --install-types --non-interactive --ignore-missing-imports . || true
    - echo "âœ… Type checking completed"
  allow_failure: true  # Allow failure for now as it's informational

lint:pylint:
  stage: lint
  <<: *python_template
  script:
    - echo "ðŸ” Running Pylint analysis..."
    - pip install pylint
    - pylint --version
    - |
      pylint --rcfile=.pylintrc \
        --output-format=text \
        --reports=yes \
        --score=yes \
        $(find . -name "*.py" -not -path "./.venv/*" -not -path "./.cache/*") \
        || true
    - echo "âœ… Pylint analysis completed"
  artifacts:
    reports:
      codequality: pylint-report.json
    when: always
    expire_in: 1 week
  allow_failure: true

# ==================== TESTING STAGE ====================

test:unit:
  stage: test
  <<: *python_template
  services:
    - redis:7-alpine
  variables:
    REDIS_URL: "redis://redis:6379/0"
    API_ID: "12345"
    API_HASH: "test_hash"
    BOT_TOKEN: "123456:test_token"
  before_script:
    - apt-get update -qq && apt-get install -y -qq git curl build-essential
    - python -m pip install --upgrade pip
    - pip install virtualenv
    - virtualenv .venv
    - source .venv/bin/activate
    - pip install -r requirements_enhanced.txt
    - pip install pytest pytest-asyncio pytest-mock pytest-cov pytest-xdist
    - playwright install chromium
  script:
    - echo "ðŸ§ª Running unit tests..."
    - |
      pytest tests/ \
        -v \
        --cov=. \
        --cov-report=xml \
        --cov-report=html \
        --cov-report=term \
        --junit-xml=junit-report.xml \
        --maxfail=5 \
        -x
    - echo "âœ… Unit tests completed"
  coverage: '/TOTAL.*\s+(\d+%)$/'
  artifacts:
    reports:
      junit: junit-report.xml
      coverage_report:
        coverage_format: cobertura
        path: coverage.xml
    paths:
      - htmlcov/
      - coverage.xml
    when: always
    expire_in: 1 week

test:integration:
  stage: test
  <<: *python_template
  services:
    - redis:7-alpine
  variables:
    REDIS_URL: "redis://redis:6379/0"
    API_ID: "12345"
    API_HASH: "test_hash"
    BOT_TOKEN: "123456:test_token"
  before_script:
    - apt-get update -qq && apt-get install -y -qq git curl build-essential
    - python -m pip install --upgrade pip
    - pip install virtualenv
    - virtualenv .venv
    - source .venv/bin/activate
    - pip install -r requirements_enhanced.txt
    - pip install pytest pytest-asyncio pytest-mock
    - playwright install chromium
  script:
    - echo "ðŸ”— Running integration tests..."
    - pytest tests/ -m "integration" -v --tb=short || true
    - echo "âœ… Integration tests completed"
  allow_failure: true

test:performance:
  stage: test
  <<: *python_template
  script:
    - echo "âš¡ Running performance tests..."
    - pip install pytest-benchmark
    - pytest tests/ -m "performance" -v --benchmark-only || true
    - echo "âœ… Performance tests completed"
  allow_failure: true

# ==================== SECURITY STAGE ====================

security:bandit:
  stage: security
  <<: *python_template
  script:
    - echo "ðŸ”’ Running Bandit security scan..."
    - pip install bandit[toml]
    - bandit --version
    - |
      bandit -r . \
        -f json \
        -o bandit-report.json \
        --exclude .venv,.cache,tests \
        --skip B101,B601 \
        || true
    - bandit -r . --exclude .venv,.cache,tests --format txt || true
    - echo "âœ… Security scan completed"
  artifacts:
    reports:
      sast: bandit-report.json
    when: always
    expire_in: 1 week
  allow_failure: true

security:safety:
  stage: security
  <<: *python_template
  script:
    - echo "ðŸ›¡ï¸ Running Safety vulnerability check..."
    - pip install safety
    - safety --version
    - safety check --json --output safety-report.json || true
    - safety check || true
    - echo "âœ… Vulnerability check completed"
  artifacts:
    paths:
      - safety-report.json
    when: always
    expire_in: 1 week
  allow_failure: true

security:semgrep:
  stage: security
  image: returntocorp/semgrep:latest
  script:
    - echo "ðŸ” Running Semgrep security analysis..."
    - semgrep --config=auto --json --output=semgrep-report.json . || true
    - semgrep --config=auto . || true
    - echo "âœ… Semgrep analysis completed"
  artifacts:
    reports:
      sast: semgrep-report.json
    when: always
    expire_in: 1 week
  allow_failure: true

# ==================== BUILD STAGE ====================

build:docker:
  stage: build
  image: docker:24-dind
  services:
    - docker:24-dind
  variables:
    DOCKER_HOST: tcp://docker:2376
    DOCKER_TLS_CERTDIR: "/certs"
  before_script:
    - docker info
    - echo $CI_REGISTRY_PASSWORD | docker login -u $CI_REGISTRY_USER --password-stdin $CI_REGISTRY
  script:
    - echo "ðŸ³ Building Docker image..."
    - |
      docker build \
        -f Dockerfile.enhanced \
        -t $CI_REGISTRY_IMAGE:$CI_COMMIT_SHA \
        -t $CI_REGISTRY_IMAGE:latest \
        --build-arg BUILD_DATE=$(date -u +'%Y-%m-%dT%H:%M:%SZ') \
        --build-arg VCS_REF=$CI_COMMIT_SHA \
        --build-arg VERSION=$CI_COMMIT_TAG \
        .
    - docker push $CI_REGISTRY_IMAGE:$CI_COMMIT_SHA
    - docker push $CI_REGISTRY_IMAGE:latest
    - echo "âœ… Docker image built and pushed"
  rules:
    - if: $CI_COMMIT_BRANCH == "main"
    - if: $CI_COMMIT_TAG

build:artifacts:
  stage: build
  <<: *python_template
  script:
    - echo "ðŸ“¦ Creating build artifacts..."
    - mkdir -p dist/
    - cp -r services/ dist/
    - cp -r utils/ dist/
    - cp -r handlers/ dist/
    - cp bot_enhanced.py dist/
    - cp requirements_enhanced.txt dist/
    - cp constants.py exceptions.py dist/
    - tar -czf pinfairy-bot-$CI_COMMIT_SHA.tar.gz dist/
    - echo "âœ… Build artifacts created"
  artifacts:
    paths:
      - pinfairy-bot-$CI_COMMIT_SHA.tar.gz
      - dist/
    expire_in: 1 month
  rules:
    - if: $CI_COMMIT_BRANCH == "main"
    - if: $CI_COMMIT_TAG

# ==================== DEPLOYMENT STAGE ====================

deploy:staging:
  stage: deploy
  image: alpine:latest
  before_script:
    - apk add --no-cache curl
  script:
    - echo "ðŸš€ Deploying to staging environment..."
    - |
      if [ -n "$STAGING_WEBHOOK_URL" ]; then
        curl -X POST "$STAGING_WEBHOOK_URL" \
          -H "Content-Type: application/json" \
          -d "{
            \"image\": \"$CI_REGISTRY_IMAGE:$CI_COMMIT_SHA\",
            \"environment\": \"staging\",
            \"commit\": \"$CI_COMMIT_SHA\",
            \"branch\": \"$CI_COMMIT_BRANCH\"
          }"
        echo "âœ… Staging deployment triggered"
      else
        echo "âš ï¸ STAGING_WEBHOOK_URL not configured"
      fi
  environment:
    name: staging
    url: $STAGING_URL
  rules:
    - if: $CI_COMMIT_BRANCH == "develop"
  when: manual

deploy:production:
  stage: deploy
  image: alpine:latest
  before_script:
    - apk add --no-cache curl
  script:
    - echo "ðŸš€ Deploying to production environment..."
    - |
      if [ -n "$PRODUCTION_WEBHOOK_URL" ]; then
        curl -X POST "$PRODUCTION_WEBHOOK_URL" \
          -H "Content-Type: application/json" \
          -d "{
            \"image\": \"$CI_REGISTRY_IMAGE:$CI_COMMIT_SHA\",
            \"environment\": \"production\",
            \"commit\": \"$CI_COMMIT_SHA\",
            \"tag\": \"$CI_COMMIT_TAG\"
          }"
        echo "âœ… Production deployment triggered"
      else
        echo "âš ï¸ PRODUCTION_WEBHOOK_URL not configured"
      fi
  environment:
    name: production
    url: $PRODUCTION_URL
  rules:
    - if: $CI_COMMIT_TAG
  when: manual

# ==================== NOTIFICATION JOBS ====================

notify:success:
  stage: deploy
  image: alpine:latest
  before_script:
    - apk add --no-cache curl
  script:
    - echo "ðŸ“¢ Sending success notification..."
    - |
      if [ -n "$TELEGRAM_BOT_TOKEN" ] && [ -n "$TELEGRAM_CHAT_ID" ]; then
        curl -s -X POST "https://api.telegram.org/bot$TELEGRAM_BOT_TOKEN/sendMessage" \
          -d chat_id="$TELEGRAM_CHAT_ID" \
          -d text="âœ… Pinfairy Bot pipeline succeeded!
        
        ðŸ”— Commit: $CI_COMMIT_SHA
        ðŸŒ¿ Branch: $CI_COMMIT_BRANCH  
        ðŸ‘¤ Author: $GITLAB_USER_NAME
        ðŸ“ Message: $CI_COMMIT_MESSAGE
        ðŸ”— Pipeline: $CI_PIPELINE_URL"
      fi
  rules:
    - if: $CI_COMMIT_BRANCH == "main"
    - if: $CI_COMMIT_TAG
  when: on_success

notify:failure:
  stage: deploy
  image: alpine:latest
  before_script:
    - apk add --no-cache curl
  script:
    - echo "ðŸ“¢ Sending failure notification..."
    - |
      if [ -n "$TELEGRAM_BOT_TOKEN" ] && [ -n "$TELEGRAM_CHAT_ID" ]; then
        curl -s -X POST "https://api.telegram.org/bot$TELEGRAM_BOT_TOKEN/sendMessage" \
          -d chat_id="$TELEGRAM_CHAT_ID" \
          -d text="âŒ Pinfairy Bot pipeline failed!
        
        ðŸ”— Commit: $CI_COMMIT_SHA
        ðŸŒ¿ Branch: $CI_COMMIT_BRANCH
        ðŸ‘¤ Author: $GITLAB_USER_NAME  
        ðŸ“ Message: $CI_COMMIT_MESSAGE
        ðŸ”— Pipeline: $CI_PIPELINE_URL"
      fi
  rules:
    - if: $CI_COMMIT_BRANCH == "main"
    - if: $CI_COMMIT_TAG
  when: on_failure